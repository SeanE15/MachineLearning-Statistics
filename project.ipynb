{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://miro.medium.com/max/1400/1*7bnLKsChXq94QjtAiRn40w.png\" \n",
    "</p>\n",
    "\n",
    "### <div align=\"center\">Machine Learning and Statistics: Project</div>\n",
    "#### <div align=\"center\">Author: Sean Elliott</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div align=\"center\">Iris Fisher Dataset</div>\n",
    "\n",
    "The Iris Fisher Dataset, made famous by British statistician Ronalf Fisher in 1936, is a multivariate dataset which explores the relationships between 3 species of Iris flower. Two of the species were collected in the Gaspe peninsula which is situated along the southern shore of the St Lawrence River. This river extends out from the Matapedia Value in Quebec. Canada into the Gulf of St.Lawrence.\n",
    "\n",
    "The dataset consists of 50 samples from each of the three species of Iris - Iris Setosa, Iris Virginica and Iris Versicolor.\n",
    "\n",
    "Four distinct features were measured from each sample - the length and width of the sepals (respectively) and the length and width of the petals (again, respectively). The common unit of measurement is in centimeters.\n",
    "\n",
    "Based on the combination of the 4 distinct features; Fisher was able to develop a linear discriminant model to distinguish the 4 species from one another.\n",
    "\n",
    "As the dataset has grown in popularity; it is commonly used as an example for statistical classification techniques in machine learning; like SVM (support vector machine) along with others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Sepal_Length  Sepal_Width  Petal_Length  Petal_Width           Class\n",
      "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
      "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
      "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
      "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
      "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
      "..            ...          ...           ...          ...             ...\n",
      "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
      "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
      "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
      "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
      "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Start by importing the csv file for the dataset\n",
    "csv_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "col_names = ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width','Class']\n",
    "iris =  pd.read_csv(csv_url, names = col_names)\n",
    "print(iris)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div align=\"center\">Project Purpose</div>\n",
    "\n",
    "The purpose of this project is to explore classification algorithms using the Fisher Iris Dataset. This project will explore classification algorithms, their purpose, and their best use cases.\n",
    "The hope is that the outcome will provide (using classification algorithms) a trained machine that uses the dataset to learn how to accurately catergorise new observations into their correct classes or groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div align=\"center\">What is Supervised Learning?</div>\n",
    "\n",
    "Supervised machine learning is a subcatergory of Machine Learning and Artificial Intelligence. It is deifned by its use of labelled datasets to train algorithms to accurately classify the data and predict accurate data outcomes. As data is fed into the model, it adjusts its 'weights' inorder that the model fits appropriately as part of the validation process. Supervised Learning helps to solve a variety of real-world problems at scale. For example after supervised learning, machine algorithms can be trained to identify and classifying spam emails and then directed to put the suspected emails into a 'spam' folder.\n",
    "\n",
    "Supervised Learning can be split into two types of problems when data mining:\n",
    "\n",
    "- Classification\n",
    "- Regression\n",
    "\n",
    "<p align=\"center\"><img src=\"https://www.simplilearn.com/ice9/free_resources_article_thumb/Regression_vs_Classification.jpg\"></p>\n",
    "\n",
    "\n",
    "#### <div align=\"center\">Classification</div>\n",
    "\n",
    "Classification uses an algorithm to accurately catergorise test data. It does this by recognising specific instances or patterns within the data and then makes a judgement using it's findings. Depending on what conclusion that the algorithm comes to; will determine how the datapoints are labelled or defined.\n",
    "\n",
    "Some common instances of classifiers are:\n",
    "\n",
    "- linear classifiers\n",
    "- support vector machines (SVM)\n",
    "- decision tress\n",
    "- k-nearest neighbour\n",
    "- random forest\n",
    "\n",
    "#### <div align=\"center\">Regression</div>\n",
    "\n",
    "Regression is used to understand the relationship between dependent and independent variables within datasets. Regression is also commonly used to make predictions on future datapoints and their \n",
    "likely trajectory (a common exmaple might be for sales projections)\n",
    "\n",
    "Some common examples of regression is:\n",
    "\n",
    "- linear regression\n",
    "- logistical regression\n",
    "- polynomial regression\n",
    "\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\"><img src=\"https://d1rwhvwstyk9gu.cloudfront.net/2021/03/Flowchart.png\"></p>\n",
    "\n",
    "### <div align=\"center\">What is Classification in Machine Learning?</div>\n",
    "\n",
    "Classification Algorithms are a supervised learning technique used to catergories new observations. In other words it is a program which is taught to recognise patterns in a dataset, so that when  given a new, unseen dataset, it will be able to find the same or similar patterns.\n",
    "\n",
    "There are 3 types of Classification:\n",
    "\n",
    "1) Binary Classification\n",
    "2) Multi-class Classification\n",
    "3) Multi-Label Classification or Decision Trees\n",
    "\n",
    "<p align=\"center\"><img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2023/05/image-6.png\"></p>\n",
    "\n",
    "### <p align=\"center\">Binary Classification</p>\n",
    "\n",
    "When a dataset provides a set of distinct features describing each datapoint, the output model delivered will have binary labels representing two classes of data; for example true or false, positive or negative. Examples of Binary Classification algorithms are: Logistic Regression or SVM (Support Vector Machine) algorithms.\n",
    "\n",
    "### <p align=\"center\">Multi-class Classification</p>\n",
    "\n",
    "In Multi-class Classification two or more outcome models are provided. The subtypes are one vs all/one vs rest and multi-class classification algorithms. Multi-class does not rely on binary models and classifies the dataset into multiple classes. Multi-class makes the assumption that each sample is assigned to one and only one label. Examples of Multi-class Classification algorithms are: Random forest, Naive Bayes or k-NN (K-Nearest Neighbours) - note that some of these can be used for binary and multi-class classification!\n",
    "\n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/v2/resize:fit:688/1*bcLAJfWN2GpVQNTVOCrrvw.png\"></p>\n",
    "\n",
    "### <p align=\"center\">Multi-Label Classification or Decision Trees</p>\n",
    "\n",
    "Decision Tree is a non-parametric supervised learning algorithm for classification and regression tasks. It uses a heirarchical structure consisting of root nodes, branches, internal ndoes and leaf nodes. The decision tree depicts decisions and their potential outcomes. It alkso incorporates chance into it's output model. The algorithmic model uses conditional control statements to form its decisions. The Decision Tree starts with a root node and ends with the decision being made by the leaf nodes. Some examples of Multi-Label Classification algorithms include: Multi-Label Decision Trees and Multi-Label Gradient Boosting.\n",
    "\n",
    "Within these classification types there are two types of learners:\n",
    "\n",
    "#### <div align=\"center\">Lazy Learners</div>\n",
    "\n",
    "A Lazy Learner first stores the input dataset before waiting for the test dataset to 'arrive' (or be produced). The classification for this learner is carried out using the training dataset's most appropriate data. The Lazy Learner spends less time training to spot patterns and more time on prediciting outcomes. It does have some advantages, it is most appropriate when the dataset is small and more data is required, or when the cost of learning is high. It can however be less accurate than Eager Learner algorithms as it does not have access to all of the training data when it builds its inital models. Lazy Learners delay the learning process until new data is available, this can reduce the amount of data that needs to be processed which can save time and resources. It can also improve accuracy in some regard because the data is more likely to be representative of a real work situation. It can also help to prevent overfitting as the model is only trained on relevant data. \n",
    "\n",
    "##### Advantages of Lazy Learners:\n",
    "\n",
    "- Very useful when not all the data is available.\n",
    "- Lazy Learning is not prone to suffering from data interference - meaning that collecting data about an operating regime won't affect the modelling performance.\n",
    "- Lazy Learnings problem solving capabilities increase with every newly presented case.\n",
    "- Lazy Learners can be simultaneously applied to multiple problems.\n",
    "\n",
    "##### Disadvantages of Lazy Learners:\n",
    "\n",
    "- Possibility of high memory requirements (depending on the dataset) as every request for information requires the model to start the identification of a local model from scratch.\n",
    "- Lazy Learners tend to be slower to evaluate - this could be offset by lowering the size of the training information but could compromise accuracy.\n",
    "- If the data is 'noisy' then the case-base gets increased (as no abstraction occurs during the training phase).\n",
    "- Increased computational costs as the processor can only process a limited amoutn of training data points.\n",
    "\n",
    "Some examples of 'Lazy Learners' are: \n",
    "\n",
    "- k-NN (k-Nearest Neighbours)\n",
    "- Lazy Bayesian Rules\n",
    "- Case-based Reasoning\n",
    "\n",
    "#### <div align=\"center\">Eager Learners</div>\n",
    "\n",
    "Eager Learners consturct a classification model based on the given training data before receiving data for classification. This means the predictive model is built during the training phase - meaning that the learning process is completed before the prediciton phase begins. Eager Learners must be able to commit to a single hypothesis (or problem) that covers the entire dataset. Due to the nature of Eager Learners the training phase can take longer, but the prediciton phase can be shorter. Common uses for Eager Learners are as follows: Image Recognition, Spamdetection and time series forecasting.\n",
    "\n",
    "\n",
    "##### Advantages of Eager Learners:\n",
    "\n",
    "- Much faster than Lazy Learner algorithms in the prediciton phase.\n",
    "- Increased accuracy compared to Lazy Learner algorithms.\n",
    "- Ideal for real-time or time-sensitive applications where immediate predicitons are needed.\n",
    "\n",
    "#### Disadvantages of Eager Learners:\n",
    "\n",
    "- May contain irrelevant attributes in the data; making is 'noisy'.\n",
    "- Slower in the training phase than Lazy Learner algorithms.\n",
    "- Requires the entire dataset to present a prediciton model.\n",
    "\n",
    "Some examples of 'Eager Learners' are:\n",
    "\n",
    "- Decision Tree\n",
    "- Naive Bayes\n",
    "- ANN (Artificial Neural Networks)\n",
    "- SVM (Support Vector Machines)\n",
    "- Linear Regression\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\"><img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2023/05/image-7.png\"></p>\n",
    "\n",
    "### <div align=\"center\">What is Regression in Machine Learning?</div>\n",
    "\n",
    "\n",
    "Regression algorithms predicts an outcome using the continuous values from the provided dataset. A supervised learning regression algorithm uses real-world values to predict quantitative data like income, weight, height or probability. Regression is used to map these estimations as the algorithms distinctly label the datasets inputted.\n",
    "\n",
    "There are three types of Regression: \n",
    "\n",
    "1) Linear Regression \n",
    "2) Polynomial Regression \n",
    "3) Logistic Regression \n",
    "\n",
    "### <p align=\"center\">Linear Regression</p>\n",
    "\n",
    "This is the simplest and most preferable to use of the regression models. Linear regression applies linear equations to the inputted data. Using a straight line, the model uses two quantitative values and plots them against one another in an attempt to find a relationship between the two.\n",
    "\n",
    "### <p align=\"center\">Polynomial Regression</p>\n",
    "\n",
    "This is used to find the relationship between two quantitative values which have a non-linear relationship. It is specifically used for curvy trend datasets in fields like social science, biology and economics. These fields use a polynomial function to predict the models accuracy and complexity. In Machine Learning, Polynomial Regression can be used to predict customers lifetime value, stock prices and to track economies for example.\n",
    "\n",
    "### <p align=\"center\">Logistic Regression</p>\n",
    "\n",
    "Logistic Regression also known as the Logit Model, charts the probable chance of an event occuring. It uses datasets comprising of independent vairbales and is commonly used in predictive analytics and classification.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Iris-setosa        50\n",
       "Iris-versicolor    50\n",
       "Iris-virginica     50\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of species of flower in the dataset.\n",
    "iris['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal_Length</th>\n",
       "      <th>Sepal_Width</th>\n",
       "      <th>Petal_Length</th>\n",
       "      <th>Petal_Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sepal_Length  Sepal_Width  Petal_Length  Petal_Width\n",
       "0             5.1          3.5           1.4          0.2\n",
       "1             4.9          3.0           1.4          0.2\n",
       "2             4.7          3.2           1.3          0.2\n",
       "3             4.6          3.1           1.5          0.2\n",
       "4             5.0          3.6           1.4          0.2\n",
       "..            ...          ...           ...          ...\n",
       "145           6.7          3.0           5.2          2.3\n",
       "146           6.3          2.5           5.0          1.9\n",
       "147           6.5          3.0           5.2          2.0\n",
       "148           6.2          3.4           5.4          2.3\n",
       "149           5.9          3.0           5.1          1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out values for the indepedent features and store them in variable x.\n",
    "x=iris.iloc[:,:4]\n",
    "# print out the dependent features and store them in vairbale y.\n",
    "y=iris.iloc[:,4]\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p align=\"center\">Logistic Regression</p>\n",
    "\n",
    "We start by doing the most basic regression test using a machine learning algorithm: The Logistic Regression algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split to train the algorithm.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the dataset into 4 arrays, 2 for training the algorithm (independent and dependent features) and 2 for the test (which the algorithm won't see).\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-versicolor', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-setosa', 'Iris-virginica', 'Iris-versicolor', 'Iris-setosa',\n",
       "       'Iris-virginica', 'Iris-setosa', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-setosa', 'Iris-setosa', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-setosa', 'Iris-setosa', 'Iris-versicolor',\n",
       "       'Iris-virginica', 'Iris-setosa', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-virginica', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-virginica',\n",
       "       'Iris-setosa', 'Iris-versicolor', 'Iris-versicolor', 'Iris-setosa',\n",
       "       'Iris-versicolor', 'Iris-setosa', 'Iris-setosa', 'Iris-virginica'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model=LogisticRegression()\n",
    "\n",
    "# we now train the model using the .fit() method and the x_train and y_train arguments.\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "# the program stores the prediction for x_test in y_test.\n",
    "y_pred=model.predict(x_test)\n",
    "\n",
    "#print out the predictions.\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  0,  0],\n",
       "       [ 0, 13,  1],\n",
       "       [ 0,  0, 12]], dtype=int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import two fucntions - accuracy score and confusion matrix.\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "#calculate the confusion matrix using the model's predictions using two arguments - y_test (actual results) and y_pred (predictions).\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Logistic Regression model is 97.37\n"
     ]
    }
   ],
   "source": [
    "# get accuracy of the predictions by using the accuracy function on the actual results and the predicted results and multiplying by 100 (for a percentage).\n",
    "accuracy=accuracy_score(y_test,y_pred)*100\n",
    "\n",
    "# print results to 2 decimal places.\n",
    "print(\"Accuracy of the Logistic Regression model is {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <p align=\"center\">Results of Logistic Regression - Explained</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Iris_flower_data_set\n",
    "\n",
    "https://en.wikipedia.org/wiki/Gasp%C3%A9_Peninsula\n",
    "\n",
    "https://www.simplilearn.com/tutorials/machine-learning-tutorial/classification-in-machine-learning#:~:text=Based%20on%20training%20data%2C%20the,into%20various%20classes%20or%20groups. - Date Accessed: 04/11/2023\n",
    "\n",
    "https://builtin.com/machine-learning/classification-machine-learning - Date Accessed: 04/11/2023 \n",
    "\n",
    "https://www.autoblocks.ai/glossary/lazy-learning - Date Accessed: 04/11/2023  \n",
    "\n",
    "https://www.engati.com/glossary/lazy-learning#:~:text=set%20of%20attributes.-,What%20are%20some%20examples%20of%20lazy%20learning%3F,some%20examples%20of%20lazy%20learning - Date Accessed: 04/11/2023  \n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2023/02/lazy-learning-vs-eager-learning-algorithms-in-machine-learning/ - Date Accessed: 04/11/2023\n",
    "\n",
    "https://www.datacamp.com/blog/what-is-eager-learning - Date Accessed: 04/11/2023\n",
    "\n",
    "https://www.ibm.com/topics/supervised-learning - Date Accessed: 04/11/2023\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2023/05/regression-vs-classification/ - Date Accessed: 04/11/2023\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2021/08/decision-tree-algorithm/ - Date Accessed: 04/11/2023\n",
    "\n",
    "https://www.datacamp.com/blog/classification-machine-learning - Date Accessed: 04/11/2023"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
